from numpy import  *
from math import log
def loadSimpData():
    dataMat = matrix([[1., 2.1],
                      [2., 1.1],
                      [1.3, 1.],
                      [1., 1.],
                      [2., 1.]])
    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]
    return dataMat, classLabels

'''
首先对数据集构建单层决策树，然后再对每个决策树分类器赋予不同的权值，将其组合成一个大的分类器，
由迭代得到多个弱分类器，每一次迭代，都有一个固定的样本的权重值，根据这些样本去构建单层决策树
而构建单层决策树，可以有不同的阈值，不同的分类特征和不同的分类决策方式(大于判-1或小于判-1)来构建，
故在其中选择最佳的单层决策树，构建完这个决策树，在这个决策树的基础上，对样本的权重进行调整，再得到
一个最佳单层决策树，将这些单层决策树按权值alpha组合在一起，alpha值是根据每个弱分类器的错误率决定的
'''

def stumpClassify(dataMatrix, dimen, threshVal, threshIneq):
    '''
    这是一个通过阈值threshVal对样本进行分类的，所有在阈值一边的数据会分到类别-1，而在另外一边的数据分到类别+1
    :param dataMatrix: 样本数据集，按列表形式输入
    :param dimen: 用于指定切分的特征
    :param threshVal: 作为dimen所指定的特征列的值的比较阈值
    :param threshIneq: 用来指定是大于还是小于阈值，样本类别由-1和1，这个是指定方式
    :return: 决策之后的类别标签，数组形式
    '''
    retArray = ones((dataMatrix.shape[0], 1))
    if threshIneq == 'less_than':
        retArray[dataMatrix[:, dimen] <= threshVal] = -1.0
    else:
        retArray[dataMatrix[:, dimen] > threshVal] = -1.0
    return retArray


def buildStump(dataArr, classLabels, D):
    '''
    循环每个特征向量，用此特征向量计算出j个阈值，
    比较各阈值划分数据得到的结果的错误率，选最小错误率的划分方法当树桩
    :param dataArr: numpy.ndarray形式的样本数据集
    :param classLabels:numpy.ndarray形式的类别标签
    :param D:当前轮次样本的权重向量
    :return:bestStump最佳单层决策树的相关信息，minError最佳单层决策树的错误率，即最小错误率
            bestClassESt当前最佳单层决策树的类别估计值
    '''
    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T
    m, n = dataMatrix.shape
    # bestStump存储给定权重向量是得到的最佳单层决策树的相关信息
    # bestClassEst 当前最佳单层决策树的类别估计值
    numSteps = 10.0; bestStump = {}; bestClassEst = mat(zeros((m, 1)))
    minError = inf
    # 遍历所有特征
    for i in range(n):
        rangeMin = dataMatrix[:, i].min(); rangeMax = dataMatrix[:, i].max()
        stepSize = (rangeMax - rangeMin) / numSteps
        # 遍历所有阈值
        for j in range(-1, int(numSteps)+1):
            for inequal in ['1ess_than', 'greater_than']:
                # 阈值=最小值+步数*步幅，逐步提高阈值
                threshVal = (rangeMin + float(j) * stepSize)
                # 按照第i个特征对样本进行分类，把大于小于阈值都试一下，得出判定结果再计算错误率，最终选择错误率最低的作为树状。
                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)
                # 看各样本的预测值和类别值是否相等，不等的将值为1
                errArr = mat(ones((m, 1)))
                errArr[predictedVals == labelMat] = 0
                # 计算得到加权错误率
                weightedError = D.T * errArr
                # 将加权错误率与最小错误率，所有循环完成后，最终得到一个最小错误率，这个错误率的单层决策树就是最佳单层决策树
                if weightedError < minError:
                    minError = weightedError
                    bestClassEst = predictedVals.copy()
                    bestStump['dim'] = i# 最佳分类特征
                    bestStump['thresh'] = threshVal# 最佳阈值
                    bestStump['ineq'] = inequal# 最佳判定符号 即是大于阈值算-1类还是小于阈值算-1类
    return bestStump, minError, bestClassEst



def adaBoostTrainDS(dataArr, classLabels, numIT = 100):
    '''
    基于单层决策树的AdaBoost算法
    :param dataArr: numpy.ndarray形式的样本数据集
    :param classLabels: numpy.ndarray形式的类别标签
    :param numIT: 迭代次数
    :return: 多个弱分类器组成的numpy.ndarray形式的分类器集合
    '''
    weakClassArr = []
    m = dataArr.shape[0]
    # 向量D包含每数据点的权重，一开始赋予每个数据点相同的权重
    D = mat(ones((m, 1)) / m)
    # 记录每个数据点的类别估计累计值
    aggClassEst = mat(zeros((m, 1)))
    # 对于每次迭代，找到最佳的单层决策树，将最佳单层决策树添加到决策树组
    for i in range(numIT):
        bestStump, error, classEst = buildStump(dataArr, classLabels, D)
        # print("D: ", D.T)
        # alpha值是对每个弱分类器的权重
        # max(error,1e-16)用于确保没有错误时不会出现除零溢出
        alpha = float(0.5*log((1.0 - error) / max(error, 1e-16)))
        bestStump['alpha'] = alpha
        weakClassArr.append(bestStump)
        #print("classEst: ", classEst.T)
        # 对样本进行权重更新D(t+1)=D(t)*exp(-predict*label*alpha)
        # 如果分类正确，D(t+1) = D(t)*exp(-alpha)/sum(D)即预测值和类别值同正负，得到的为1，
        # 预测错误D(t+1) = D(t)*exp(alpha)/sum(D)则predict,label两值相乘为-1，满足D的更新原则，
        expon = multiply(-1*alpha*mat(classLabels).T, classEst)
        D = multiply(D, exp(expon))
        D = D / D.sum()
        # 更新当前组合分类器的决策树
        aggClassEst += alpha*classEst
        #print("aggClassEst: ",aggClassEst.T)
        # 组合分类器的类别估计值
        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T, ones((m, 1)))
        errorRate = aggErrors.sum() / m
        # print("the total error: ", errorRate, "\n")
        if errorRate == 0.0: break# 分类无误则提前结束迭代
    return weakClassArr, errorRate



def adaClassify(datToClass, classifierArr):
    dataMatrix = mat(datToClass)
    m = dataMatrix.shape[0]
    aggClassEst = mat(zeros((m, 1)))
    for i in range(len(classifierArr)):
        classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'],classifierArr[i]['thresh'],classifierArr[i]['ineq'])
        aggClassEst += classifierArr[i]['alpha']*classEst
        print(aggClassEst)
    return sign(aggClassEst)



# 自适应数据加载函数
def loadDataSet(filename):
    numFeat = len(open(filename).readline().split('\t'))
    dataMat = []; labelMat = []
    fr = open(filename)
    for line in fr.readlines():
        lineArr = []
        curLine = line.strip().split('\t')
        for i in range(numFeat - 1):
            lineArr.append(float(curLine[i]))
        dataMat.append(lineArr)
        labelMat.append(float(curLine[-1]))
    return dataMat, labelMat


filename = 'D:/ML/horseColicTraining.txt'
dataMat, labelArr = loadDataSet(filename)
weakClassArr, errorRate = adaBoostTrainDS(mat(dataMat), labelArr)
print("the classArr is: ",weakClassArr, '\n',"the errorRate is: ",errorRate)

filename2 = "D:/ML/horseColicTest.txt"
testArr, testLabelArr = loadDataSet(filename2)
weakClassArr, errorRate = adaBoostTrainDS(mat(testArr), testLabelArr)
print("the test_classArr is: ",weakClassArr, '\n',"the test_errorRate is: ",errorRate)

# ROC曲线的绘制及AUC计算函数
def plotROC(predStrengths, classLabels):
    import matplotlib.pyplot as plt
    cur = (1.0, 1.0)
    ySUm = 0.0
    numPosClas = sum(array(classLabels) == 1.0)
